base_paper_id,variant_type,title,rating,decision,meta_review,strengths,weaknesses
PCm1oT8pZI,original,Safe and Robust Watermark Injection with a Single OoD Image [original],3.0,Reject,"The paper proposes a watermarking technique that leverages a single out-of-distribution (OoD) image as a secret key for IP verification. The authors propose a weight perturbation strategy to improve the robustness of the watermark against common removal attacks, such as fine-tuning, pruning, and model extraction. The experimental results demonstrate that the proposed watermarking approach is both time- and sample-efficient without training data and is robust against the watermark removal attacks mentioned above.

However, the reviewers raised concerns about the novelty of the proposed method, the lack of comparison with other methods, and the limited evaluation on large-scale datasets. The authors did not provide a rebuttal to address these concerns. Therefore, I recommend rejecting the paper.

### justification_for_why_not_higher_score

The reviewers raised concerns about the novelty of the proposed method, the lack of comparison with other methods, and the limited evaluation on large-scale datasets. The authors did not provide a rebuttal to address these concerns.

### justification_for_why_not_lower_score

N/A

","['1. The proposed method is based on a single out-of-distribution (OoD) image as a secret key for IP verification, which is more practical and efficient compared to existing methods that require a large amount of data.\n2. The proposed method is robust against common watermark removal attacks, such as fine-tuning, pruning, and model extraction.\n\n', '1. The paper is well-written and easy to follow.\n2. The proposed method is simple and effective.\n3. The experimental results demonstrate the effectiveness of the proposed method.\n\n', '1. The paper is well-written and easy to follow.\n2. The proposed method is simple and effective.\n3. The experimental results demonstrate the effectiveness of the proposed method.\n\n', '1. The paper is well-written and easy to follow.\n2. The proposed method is simple and effective.\n3. The experimental results demonstrate the effectiveness of the proposed method.\n\n']","['1. The proposed method is only evaluated on three benchmarks, which is not sufficient to demonstrate its effectiveness. It is recommended to evaluate the method on more benchmarks to show its generalization ability.\n2. The proposed method is not compared with existing methods that use OoD data for watermarking, such as [1]. It is recommended to compare the proposed method with these existing methods to show its advantages.\n3. The proposed method is not compared with existing methods that use a single image for watermarking, such as [2]. It is recommended to compare the proposed method with these existing methods to show its advantages.\n4. The proposed method is not evaluated on large-scale datasets, such as ImageNet. It is recommended to evaluate the method on large-scale datasets to show its effectiveness in practical scenarios.\n5. The proposed method is not evaluated on real-world datasets, such as real-world images of animals. It is recommended to evaluate the method on real-world datasets to show its effectiveness in practical scenarios.\n\n[1] Li, Y., & Wang, R. (2022). Data-Free Watermarking for Deep Neural Networks. arXiv preprint arXiv:2206.02711.\n\n[2] Li, Y., & Wang, R. (2022). Data-Free Watermarking for Deep Neural Networks. arXiv preprint arXiv:2206.02711.\n\n', '1. The proposed method is a simple extension of Asano & Saeed (2023) and Asano et al. (2019), which is not enough for ICLR.\n2. The proposed method is not compared with other methods that use OOD data for watermarking, such as [1,2].\n3. The proposed method is not compared with other methods that use a single image for watermarking, such as [3,4].\n4. The proposed method is not evaluated on large-scale datasets, such as ImageNet.\n5. The proposed method is not evaluated on real-world datasets, such as real-world images of animals.\n\n[1] Li, Y., & Wang, R. (2022). Data-Free Watermarking for Deep Neural Networks. arXiv preprint arXiv:2206.02711.\n\n[2] Li, Y., & Wang, R. (2022). Data-Free Watermarking for Deep Neural Networks. arXiv preprint arXiv:2206.02711.\n\n[3] Li, Y., & Wang, R. (2022). Data-Free Watermarking for Deep Neural Networks. arXiv preprint arXiv:2206.02711.\n\n[4] Li, Y., & Wang, R. (2022). Data-Free Watermarking for Deep Neural Networks. arXiv preprint arXiv:2206.02711.\n\n', '1. The proposed method is not compared with other methods that use OOD data for watermarking, such as [1,2].\n2. The proposed method is not compared with other methods that use a single image for watermarking, such as [3,4].\n3. The proposed method is not evaluated on large-scale datasets, such as ImageNet.\n4. The proposed method is not evaluated on real-world datasets, such as real-world images of animals.\n\n[1] Li, Y., & Wang, R. (2022). Data-Free Watermarking for Deep Neural Networks. arXiv preprint arXiv:2206.02711.\n\n[2] Li, Y., & Wang, R. (2022). Data-Free Watermarking for Deep Neural Networks. arXiv preprint arXiv:2206.02711.\n\n[3] Li, Y., & Wang, R. (2022). Data-Free Watermarking for Deep Neural Networks. arXiv preprint arXiv:2206.02711.\n\n[4] Li, Y., & Wang, R. (2022). Data-Free Watermarking for Deep Neural Networks. arXiv preprint arXiv:2206.02711.\n\n', '1. The proposed method is not compared with other methods that use OOD data for watermarking, such as [1,2].\n2. The proposed method is not compared with other methods that use a single image for watermarking, such as [3,4].\n3. The proposed method is not evaluated on large-scale datasets, such as ImageNet.\n4. The proposed method is not evaluated on real-world datasets, such as real-world images of animals.\n\n[1] Li, Y., & Wang, R. (2022). Data-Free Watermarking for Deep Neural Networks. arXiv preprint arXiv:2206.02711.\n\n[2] Li, Y., & Wang, R. (2022). Data-Free Watermarking for Deep Neural Networks. arXiv preprint arXiv:2206.02711.\n\n[3] Li, Y., & Wang, R. (2022). Data-Free Watermarking for Deep Neural Networks. arXiv preprint arXiv:2206.02711.\n\n[4] Li, Y., & Wang, R. (2022). Data-Free Watermarking for Deep Neural Networks. arXiv preprint arXiv:2206.02711.\n\n']"
PCm1oT8pZI,no_conclusion,Safe and Robust Watermark Injection with a Single OoD Image [no_conclusion],5.5,Accept,"This paper proposes a watermarking method that uses a single out-of-distribution (OOD) image as a secret key for intellectual property (IP) verification. The approach does not require access to the original training data, making it suitable for scenarios where data privacy and safety are concerns. The proposed method is shown to be robust against common watermark removal attacks, including fine-tuning, pruning, and model extraction. The paper also presents experimental results demonstrating the efficiency and effectiveness of the proposed approach.

The paper received mixed reviews, with some reviewers praising its novelty and effectiveness while others raised concerns about the motivation and potential limitations of the approach. The authors provided detailed responses to the reviewers' comments and concerns. However, the reviewers' concerns were not fully addressed.

### justification_for_why_not_higher_score

The reviewers' concerns were not fully addressed.

### justification_for_why_not_lower_score

N/A

","['The paper proposes a novel approach to watermarking that uses a single OOD image as a secret key, which is a unique and interesting idea. The paper is well-organized and easy to follow. The experimental results demonstrate the effectiveness of the proposed approach.\n\n', '1. This paper proposes a novel watermark method based on OOD data, which fills the gap of backdoor-based IP protection of deep models without training data.\n2. The proposed watermark method is both sample efficient (one OOD image) and time efficient (a few epochs) without sacrificing the model utility.\n3. The proposed method is also robust against common removal attacks, such as fine-tuning, pruning, and model extraction.\n\n', '1. The proposed method is sample efficient (one OoD image) and time efficient (a few epochs) without sacrificing the model utility.\n2. The proposed method is also robust against common removal attacks, such as fine-tuning, pruning, and model extraction.\n3. The proposed method is well motivated and easy to follow.\n\n', '1. This paper proposes a new watermarking method that leverages the diverse knowledge from a single out-of-distribution (OoD) image, which serves as a secret key for IP verification.\n2. The proposed method is sample efficient (one OoD image) and time efficient (a few epochs) without sacrificing the model utility.\n3. The proposed method is also robust against common removal attacks, such as fine-tuning, pruning, and model extraction.\n\n']","['The paper lacks a clear motivation for the proposed approach. The authors do not provide a clear explanation of why using a single OOD image as a secret key is a good idea, and how it addresses the challenges of watermarking. The paper also lacks a thorough analysis of the limitations of the proposed approach. The authors do not discuss the potential drawbacks or limitations of using a single OOD image as a secret key, such as the potential for the image to be easily compromised or stolen. The paper also lacks a discussion of the potential trade-offs between the proposed approach and other watermarking techniques. The authors do not compare the proposed approach to other watermarking techniques, and do not discuss the potential advantages and disadvantages of using a single OOD image as a secret key compared to other approaches. The paper also lacks a discussion of the potential applications of the proposed approach. The authors do not discuss how the proposed approach can be used in real-world scenarios, and do not provide examples of potential use cases. The paper also lacks a discussion of the potential ethical implications of the proposed approach. The authors do not discuss the potential ethical implications of using a single OOD image as a secret key, such as the potential for the image to be used to compromise the security of the model. Overall, the paper lacks a clear motivation, thorough analysis, and discussion of the limitations and potential applications of the proposed approach.\n\n', '1. The paper is not very clear about the motivation of the proposed method. Why do we need to use OOD data to construct the surrogate dataset? What are the advantages of using OOD data compared to using in-distribution data?\n2. The paper should provide more details about the experimental settings. For example, what is the size of the surrogate dataset? How is the surrogate dataset constructed? What are the hyperparameters used in the experiments?\n\n', '1. The proposed method requires the OoD image to be known to the model owner, which may not be practical in some scenarios.\n2. The proposed method may not be robust against model compression attacks, such as model pruning and knowledge distillation.\n\n', '1. The proposed method requires the OoD image to be known to the model owner, which may not be practical in some scenarios.\n2. The proposed method may not be robust against model compression attacks, such as model pruning and knowledge distillation.\n\n']"
PCm1oT8pZI,no_abstract,Safe and Robust Watermark Injection with a Single OoD Image [no_abstract],5.0,Reject,"The paper proposes a watermarking method that does not require training data. The method uses a single out-of-distribution image to create a surrogate dataset for fine-tuning the model with a backdoor trigger. The authors also propose a weight perturbation method to improve the robustness of the watermark against removal attacks. The paper is well-written and easy to follow. The proposed method is novel and interesting. The paper has received four reviews, with a rating of 5, 5, 5, and 5. The authors have not responded to the reviews. The reviewers have raised several concerns, including the limited evaluation of the proposed method, the lack of comparison with other existing watermarking methods, and the lack of discussion of the limitations of the proposed method. The authors are encouraged to address these concerns in a future submission.

### justification_for_why_not_higher_score

The paper has received four reviews, with a rating of 5, 5, 5, and 5. The authors have not responded to the reviews. The reviewers have raised several concerns, including the limited evaluation of the proposed method, the lack of comparison with other existing watermarking methods, and the lack of discussion of the limitations of the proposed method.

### justification_for_why_not_lower_score

N/A

","['The paper proposes a novel watermarking method that does not require access to the training data, which is a significant advantage in many real-world scenarios.\n\nThe use of a single out-of-distribution image to create a surrogate dataset for fine-tuning is a creative and efficient approach.\n\nThe weight perturbation method proposed to improve the robustness of the watermark is an interesting idea.\n\n', '1. The paper is well-written and easy to follow.\n2. The proposed method is novel and interesting.\n3. The proposed method is effective.\n\n', '1. The paper proposes a novel watermark method based on OoD data, which fills in the gap of backdoor-based IP protection of deep models without training data. The proposed method is sample efficient (one OoD image) and time efficient (a few epochs) without sacrificing the model utility.\n2. The paper proposes to adopt a weight perturbation strategy to improve the robustness of the watermarks against common removal attacks, such as fine-tuning, pruning, and model extraction. The paper shows the robustness of watermarks through extensive empirical results, and they persist even in an unfair scenario where the removal attack uses a part of in-distribution data.\n\n', '1. The paper proposes a novel watermark method based on OoD data, which fills in the gap of backdoor-based IP protection of deep models without training data. The proposed method is sample efficient (one OoD image) and time efficient (a few epochs) without sacrificing the model utility.\n2. The paper proposes to adopt a weight perturbation strategy to improve the robustness of the watermarks against common removal attacks, such as fine-tuning, pruning, and model extraction. The paper shows the robustness of watermarks through extensive empirical results, and they persist even in an unfair scenario where the removal attack uses a part of in-distribution data.\n\n']","['The evaluation of the proposed method is limited to three small datasets (CIFAR-10, CIFAR-100, and GTSRB). It would be beneficial to evaluate the method on larger and more diverse datasets to demonstrate its effectiveness.\n\nThe paper does not provide a detailed analysis of the robustness of the watermark against removal attacks. It would be helpful to provide a more comprehensive evaluation of the robustness of the watermark against various types of attacks.\n\nThe paper does not compare the proposed method with other existing watermarking methods that do not require access to the training data. It would be beneficial to compare the proposed method with these existing methods to demonstrate its effectiveness.\n\n', '1. The paper lacks a discussion of the limitations of the proposed method.\n2. The paper lacks a discussion of the potential risks and challenges associated with the proposed method.\n3. The paper lacks a discussion of the potential ethical implications of the proposed method.\n\n', '1. The paper lacks a discussion of the limitations of the proposed method. \n2. The paper lacks a discussion of the potential risks and challenges associated with the proposed method.\n3. The paper lacks a discussion of the potential ethical implications of the proposed method.\n\n', '1. The paper lacks a discussion of the limitations of the proposed method. \n2. The paper lacks a discussion of the potential risks and challenges associated with the proposed method.\n3. The paper lacks a discussion of the potential ethical implications of the proposed method.\n\n']"
PCm1oT8pZI,no_introduction,Safe and Robust Watermark Injection with a Single OoD Image [no_introduction],4.5,Reject,"This paper proposes a watermarking method that does not require training data and utilizes a single out-of-distribution image. The authors design a robust weight perturbation method to defend against watermark removal attacks. The proposed method is evaluated on three benchmarks and shows good performance.

The reviewers generally agree that the paper is well-written and easy to follow. However, they also raised some concerns about the novelty of the proposed method, the sufficiency of the experiments, and the robustness of the proposed method against different types of attacks.

### justification_for_why_not_higher_score

The novelty of the proposed method is limited, the experiments are not sufficient, and the robustness of the proposed method is not fully evaluated.

### justification_for_why_not_lower_score

N/A

","['1. The paper is well-written and easy to follow.\n2. The proposed method is simple and effective.\n3. The experimental results show that the proposed method is robust against watermark removal attacks.\n\n', '1. This paper proposes a new watermarking method that does not require training data and utilizes a single out-of-distribution image.\n2. The proposed method is simple and effective.\n3. The experimental results show that the proposed method is robust against watermark removal attacks.\n\n', '1. The paper is well-written and easy to follow.\n2. The proposed method is simple and effective.\n3. The experimental results show that the proposed method is robust against watermark removal attacks.\n\n', '1. The paper is well-written and easy to follow.\n2. The proposed method is simple and effective.\n3. The experimental results show that the proposed method is robust against watermark removal attacks.\n\n']","['1. The novelty of this paper is limited. The proposed method is based on the previous work [1], which also uses a single out-of-distribution image for watermarking. The only difference is that the authors use the generated data for fine-tuning the same model instead of distilling a new model. The novelty of this paper is not significant.\n2. The experiments are not sufficient. The proposed method is only evaluated on three benchmarks, which is not enough to demonstrate its effectiveness. Moreover, the proposed method is only compared with one baseline, which is not enough to demonstrate its superiority. \n3. The robustness of the proposed method is not fully evaluated. The authors only evaluate the robustness of the proposed method against three watermark removal attacks, which is not enough to demonstrate its robustness. Moreover, the authors do not evaluate the robustness of the proposed method against other types of attacks, such as adversarial attacks.\n\n[1] Li, Y., & Wang, X. (2022). Data-free watermark injection for deep neural networks. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 10282-10291).\n\n', '1. The novelty of this paper is limited. The proposed method is based on the previous work [1], which also uses a single out-of-distribution image for watermarking. The only difference is that the authors use the generated data for fine-tuning the same model instead of distilling a new model. The novelty of this paper is not significant.\n2. The experiments are not sufficient. The proposed method is only evaluated on three benchmarks, which is not enough to demonstrate its effectiveness. Moreover, the proposed method is only compared with one baseline, which is not enough to demonstrate its superiority. \n3. The robustness of the proposed method is not fully evaluated. The authors only evaluate the robustness of the proposed method against three watermark removal attacks, which is not enough to demonstrate its robustness. Moreover, the authors do not evaluate the robustness of the proposed method against other types of attacks, such as adversarial attacks.\n\n[1] Li, Y., & Wang, X. (2022). Data-free watermark injection for deep neural networks. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 10282-10291).\n\n', '1. The novelty of this paper is limited. The proposed method is based on the previous work [1], which also uses a single out-of-distribution image for watermarking. The only difference is that the authors use the generated data for fine-tuning the same model instead of distilling a new model. The novelty of this paper is not significant.\n2. The experiments are not sufficient. The proposed method is only evaluated on three benchmarks, which is not enough to demonstrate its effectiveness. Moreover, the proposed method is only compared with one baseline, which is not enough to demonstrate its superiority. \n3. The robustness of the proposed method is not fully evaluated. The authors only evaluate the robustness of the proposed method against three watermark removal attacks, which is not enough to demonstrate its robustness. Moreover, the authors do not evaluate the robustness of the proposed method against other types of attacks, such as adversarial attacks.\n\n[1] Li, Y., & Wang, X. (2022). Data-free watermark injection for deep neural networks. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 10282-10291).\n\n', '1. The novelty of this paper is limited. The proposed method is based on the previous work [1], which also uses a single out-of-distribution image for watermarking. The only difference is that the authors use the generated data for fine-tuning the same model instead of distilling a new model. The novelty of this paper is not significant.\n2. The experiments are not sufficient. The proposed method is only evaluated on three benchmarks, which is not enough to demonstrate its effectiveness. Moreover, the proposed method is only compared with one baseline, which is not enough to demonstrate its superiority. \n3. The robustness of the proposed method is not fully evaluated. The authors only evaluate the robustness of the proposed method against three watermark removal attacks, which is not enough to demonstrate its robustness. Moreover, the authors do not evaluate the robustness of the proposed method against other types of attacks, such as adversarial attacks.\n\n[1] Li, Y., & Wang, X. (2022). Data-free watermark injection for deep neural networks. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 10282-10291).\n\n']"
PCm1oT8pZI,no_experiments,Safe and Robust Watermark Injection with a Single OoD Image [no_experiments],4.5,Reject,"The paper proposes a watermarking method for DNNs that relies on a single OoD image to generate surrogate data and a weight perturbation strategy to make the watermark robust against attacks. The authors evaluate the method on three datasets and show that it is effective in injecting watermarks and is robust against watermark removal attacks.

The reviewers raised several concerns about the novelty of the proposed method, the limited evaluation of the proposed method, and the lack of comparison with existing watermarking methods. The authors provided some responses to these concerns, but the reviewers remained unconvinced about the novelty of the proposed method and the evaluation of the proposed method.

### justification_for_why_not_higher_score

The reviewers raised several concerns about the novelty of the proposed method, the limited evaluation of the proposed method, and the lack of comparison with existing watermarking methods. The authors provided some responses to these concerns, but the reviewers remained unconvinced about the novelty of the proposed method and the evaluation of the proposed method.

### justification_for_why_not_lower_score

N/A

","['1. The proposed method is simple and effective. It uses a single OoD image to create a surrogate dataset for watermarking, which is more efficient than using a large number of in-distribution (ID) samples. The weight perturbation strategy also improves the robustness of the watermark against removal attacks.\n2. The paper provides extensive experiments to demonstrate the effectiveness of the proposed method. The experiments show that the proposed method is effective in injecting watermarks and is robust against watermark removal attacks.\n\n', '- The paper proposes a new method for watermarking DNNs that does not rely on the original training data and uses a single OoD image to generate surrogate data. This makes the method more practical and efficient.\n- The paper introduces a weight perturbation strategy to improve the robustness of the watermark against attacks. This is an interesting approach that can be used to make the watermark more robust.\n- The paper evaluates the method on three datasets and shows that it is effective in injecting watermarks and is robust against watermark removal attacks.\n\n', '- The proposed method is simple and effective. It uses a single OoD image to create a surrogate dataset for watermarking, which is more efficient than using a large number of in-distribution (ID) samples. The weight perturbation strategy also improves the robustness of the watermark against removal attacks.\n- The paper provides extensive experiments to demonstrate the effectiveness of the proposed method. The experiments show that the proposed method is effective in injecting watermarks and is robust against watermark removal attacks.\n- The proposed method is applicable to a wide range of watermarking scenarios, including federated learning, where the server does not have access to any in-distribution data.\n\n', 'The paper is well-written and easy to follow. The proposed method is simple and effective. The authors also provide a detailed comparison with several baseline methods.\n\n']","['1. The proposed method is not novel. The idea of using a single OoD image to create a surrogate dataset for watermarking has been explored in previous works [1,2]. The weight perturbation strategy is also not new.\n2. The experiments are not convincing. The paper only evaluates the proposed method on three small datasets. The results on larger datasets are not provided. The paper also does not compare the proposed method with other state-of-the-art watermarking methods.\n3. The paper does not discuss the limitations of the proposed method. For example, the proposed method may not work well for large models or datasets.\n\n[1] Li, Y., & Wang, R. (2022). Data-free watermarking for deep neural networks. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 15944-15953).\n\n[2] Asano, T., & Saeed, A. N. (2023). One Image is Enough: Data-Free Model Compression with a Single Image. arXiv preprint arXiv:2301.13023.\n\n', '- The paper does not provide a detailed comparison with existing watermarking methods. It would be helpful to compare the proposed method with existing methods in terms of accuracy, robustness, and efficiency.\n- The paper does not provide a detailed analysis of the robustness of the watermark against different types of attacks. It would be helpful to evaluate the method against a wider range of attacks, such as pruning, distillation, and model extraction attacks.\n- The paper does not provide a detailed analysis of the computational cost of the method. It would be helpful to compare the computational cost of the proposed method with existing methods.\n\n', '- The paper does not provide a detailed comparison with existing watermarking methods. It would be helpful to compare the proposed method with existing methods in terms of accuracy, robustness, and efficiency.\n- The paper does not provide a detailed analysis of the robustness of the watermark against different types of attacks. It would be helpful to evaluate the method against a wider range of attacks, such as pruning, distillation, and model extraction attacks.\n- The paper does not provide a detailed analysis of the computational cost of the method. It would be helpful to compare the computational cost of the proposed method with existing methods.\n\n', '1. The proposed method is not novel. The idea of using a single out-of-distribution image to construct a surrogate dataset has been explored in previous works [1,2]. The weight perturbation strategy is also not new.\n2. The experiments are not convincing. The authors only evaluate the proposed method on three small datasets. The results on larger datasets are not provided. The authors also do not compare the proposed method with other state-of-the-art watermarking methods.\n3. The paper does not discuss the limitations of the proposed method. For example, the proposed method may not work well for large models or datasets.\n\n[1] Li, Y., & Wang, R. (2022). Data-free watermarking for deep neural networks. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 15944-15953).\n\n[2] Asano, T., & Saeed, A. N. (2023). One Image is Enough: Data-Free Model Compression with a Single Image. arXiv preprint arXiv:2301.13023.\n\n']"
PCm1oT8pZI,no_methods,Safe and Robust Watermark Injection with a Single OoD Image [no_methods],4.5,Reject,"This paper proposes a watermarking method that uses a single out-of-distribution (OoD) image to inject a backdoor watermark. The method uses a single image to generate a surrogate dataset, which is then used to fine-tune the model with weight perturbation to inject the watermark. The method is evaluated on CIFAR-10, CIFAR-100, and GTSRB datasets. The results show that the proposed method is effective in injecting watermarks and defending against watermark removal attacks.

The paper is well-written and easy to follow. The proposed method is simple and effective. The experimental results show that the proposed method is robust against watermark removal attacks, including fine-tuning, pruning, and model extraction.

However, the proposed method is not novel. The idea of using a single image to generate a surrogate dataset for watermarking has been proposed in [1]. The use of weight perturbation to improve robustness has also been proposed in [2]. The experimental results are not convincing. The evaluation of watermarking methods is usually done on a large-scale dataset such as ImageNet, not on CIFAR-10, CIFAR-100, and GTSRB. The proposed method is compared with only one baseline method, which is not enough. The proposed method is not compared with other watermarking methods that use a single out-of-distribution (OoD) image. The proposed method is not practical. The method requires a single out-of-distribution (OoD) image, which is not realistic. In real-world scenarios, the watermarking method should be able to work with any image, not just a single specific image.

### justification_for_why_not_higher_score

The proposed method is not novel. The idea of using a single image to generate a surrogate dataset for watermarking has been proposed in [1]. The use of weight perturbation to improve robustness has also been proposed in [2]. The experimental results are not convincing. The evaluation of watermarking methods is usually done on a large-scale dataset such as ImageNet, not on CIFAR-10, CIFAR-100, and GTSRB. The proposed method is compared with only one baseline method, which is not enough. The proposed method is not compared with other watermarking methods that use a single out-of-distribution (OoD) image. The proposed method is not practical. The method requires a single out-of-distribution (OoD) image, which is not realistic. In real-world scenarios, the watermarking method should be able to work with any image, not just a single specific image.

### justification_for_why_not_lower_score

N/A

","['The paper is well-written and easy to follow. The proposed method is simple and intuitive. The experimental results show that the proposed method is effective in injecting watermarks and defending against watermark removal attacks.\n\n', '1. The paper is well-written and easy to follow.\n2. The proposed method is based on a backdoor-based watermarking technique that implants verifiable backdoor triggers by poisoning training samples. This method is simple and effective.\n3. The proposed method is evaluated on three datasets, CIFAR-10, CIFAR-100, and GTSRB. The results show that the proposed method is robust against watermark removal attacks, including fine-tuning, pruning, and model extraction.\n\n', '1. The paper proposes a new watermarking method that does not require training data and uses a single OoD image, making it sample efficient and time efficient.\n2. The paper shows that the proposed method is effective against watermark removal attacks, including fine-tuning, pruning, and model extraction.\n3. The paper provides a comprehensive evaluation of the proposed method on three benchmarks, including CIFAR-10, CIFAR-100, and GTSRB.\n\n', '1. The paper is well-written and easy to follow.\n2. The proposed method is simple and effective.\n3. The experimental results show that the proposed method is robust against watermark removal attacks, including fine-tuning, pruning, and model extraction.\n\n']","['1. The proposed method is not novel. The idea of using a single image to generate a surrogate dataset for watermarking has been proposed in [1]. The use of weight perturbation to improve robustness has also been proposed in [2]. \n\n2. The experimental results are not convincing. The evaluation of watermarking methods is usually done on a large-scale dataset such as ImageNet, not on CIFAR-10, CIFAR-100, and GTSRB. The proposed method is compared with only one baseline method, which is not enough. The proposed method is not compared with other watermarking methods that use a single out-of-distribution image.\n\n3. The proposed method is not practical. The method requires a single out-of-distribution image, which is not realistic. In real-world scenarios, the watermarking method should be able to work with any image, not just a single specific image.\n\n[1] Li, J., & Wang, J. (2022). Data-free watermarking for deep neural networks. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 15198-15207).\n\n[2] Wu, D. J., He, W., & Kolter, Z. (2020). Adversarial robustness against the uniform noise attack for free. Advances in Neural Information Processing Systems, 33, 18065-18076.\n\n', '1. The proposed method is based on a backdoor-based watermarking technique that implants verifiable backdoor triggers by poisoning training samples. However, this method may not be effective for large-scale datasets, such as ImageNet.\n2. The proposed method requires a single out-of-distribution (OoD) image, which may not be realistic in real-world scenarios.\n3. The proposed method is not compared with other watermarking methods that use a single out-of-distribution (OoD) image.\n4. The proposed method is not compared with other watermarking methods that use multiple out-of-distribution (OoD) images.\n\n', '1. The paper does not provide a comprehensive comparison with existing watermarking methods, including both parameter-embedding and backdoor-based techniques. It would be helpful to include a comparison with existing methods to show the advantages of the proposed method.\n2. The paper does not provide a detailed analysis of the robustness of the proposed method against different types of watermark removal attacks. It would be helpful to provide a more detailed analysis of the robustness of the proposed method against different types of attacks.\n3. The paper does not provide a detailed analysis of the impact of the OoD image on the performance of the proposed method. It would be helpful to provide a more detailed analysis of the impact of the OoD image on the performance of the proposed method.\n\n', '1. The paper does not provide a comprehensive comparison with existing watermarking methods, including both parameter-embedding and backdoor-based techniques.\n2. The paper does not provide a detailed analysis of the robustness of the proposed method against different types of watermark removal attacks.\n3. The paper does not provide a detailed analysis of the impact of the OoD image on the performance of the proposed method.\n\n']"
