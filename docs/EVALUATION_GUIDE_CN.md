# è®ºæ–‡è¯„ä¼°ä¸åˆ†ææµç¨‹ä½¿ç”¨æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

è¿™ä¸ªè¯„ä¼°æµç¨‹åŒ…å«ä¸‰ä¸ªä¸»è¦è„šæœ¬ï¼š

1. **æµ‹è¯•è„šæœ¬** (`test_evaluation_pipeline.py`) - éªŒè¯ç¯å¢ƒé…ç½®
2. **æ‰¹é‡è¯„ä¼°** (`batch_evaluate_papers.py`) - è¯„ä¼°100ç¯‡è®ºæ–‡æ ·æœ¬
3. **ç»“æœåˆ†æ** (`analyze_evaluation_results.py`) - ç”Ÿæˆç»Ÿè®¡åˆ†æå’Œå¯è§†åŒ–

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¬¬ä¸€æ­¥ï¼šç¯å¢ƒæµ‹è¯•

è¿è¡Œæµ‹è¯•è„šæœ¬ç¡®è®¤ä¸€åˆ‡å°±ç»ªï¼š

```bash
cd D:\Mike\PycharmProjects\Researcher
python scripts/test_evaluation_pipeline.py
```

å¦‚æœæ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Œç»§ç»­ä¸‹ä¸€æ­¥ã€‚

### ç¬¬äºŒæ­¥ï¼šæ‰¹é‡è¯„ä¼°

è¯„ä¼°100ç¯‡è®ºæ–‡ï¼ˆ80ç¯‡è®­ç»ƒé›† + 20ç¯‡æµ‹è¯•é›†ï¼‰ï¼š

```bash
python scripts/batch_evaluate_papers.py
```

**é¢„è®¡è€—æ—¶**: 15-30åˆ†é’Ÿï¼ˆå–å†³äºæœºå™¨æ€§èƒ½ï¼‰

**è¾“å‡ºæ–‡ä»¶**:
- `evaluation_results/evaluation_results_YYYYMMDD_HHMMSS.jsonl`
- `evaluation_results/evaluation_summary_YYYYMMDD_HHMMSS.json`

### ç¬¬ä¸‰æ­¥ï¼šç»“æœåˆ†æ

åˆ†æè¯„ä¼°ç»“æœå¹¶ç”Ÿæˆå›¾è¡¨ï¼š

```bash
python scripts/analyze_evaluation_results.py
```

**è¾“å‡ºç›®å½•**: `analysis_output/YYYYMMDD_HHMMSS/`

åŒ…å«ï¼š
- 8ä¸ªå¯è§†åŒ–å›¾è¡¨ï¼ˆPNGï¼‰
- 5ä¸ªç»Ÿè®¡æ–‡ä»¶ï¼ˆJSON/CSVï¼‰
- 1ä¸ªè¯¦ç»†æŠ¥å‘Šï¼ˆTXTï¼‰

## ğŸ“Š ç”Ÿæˆçš„åˆ†æå†…å®¹

### 1. æ•´ä½“ç»Ÿè®¡
- å¹³å‡åˆ†ã€ä¸­ä½æ•°ã€æ ‡å‡†å·®
- å„ç»´åº¦è¯„åˆ†ï¼ˆåŸåˆ›æ€§ã€è´¨é‡ã€æ¸…æ™°åº¦ã€é‡è¦æ€§ï¼‰
- å†³ç­–åˆ†å¸ƒï¼ˆæ¥å—/æ‹’ç»æ¯”ä¾‹ï¼‰

### 2. æŒ‰å˜ä½“åˆ†æ
æ¯ç§å˜ä½“çš„ï¼š
- å¹³å‡è¯„åˆ†å’Œæ ‡å‡†å·®
- æ¥å—ç‡å’Œæ‹’ç»ç‡
- å„ç»´åº¦å¾—åˆ†

åŒ…æ‹¬çš„å˜ä½“ï¼š
- `original` - åŸå§‹è®ºæ–‡
- `no_abstract` - åˆ é™¤æ‘˜è¦
- `no_introduction` - åˆ é™¤å¼•è¨€
- `no_conclusion` - åˆ é™¤ç»“è®º
- `no_experiments` - åˆ é™¤å®éªŒ
- `no_methods` - åˆ é™¤æ–¹æ³•

### 3. æŒ‰è¯„åˆ†åŒºé—´åˆ†æ
- å·® (0-3åˆ†)
- ä¸€èˆ¬ (3-5åˆ†)
- è‰¯å¥½ (5-7åˆ†)
- ä¼˜ç§€ (7-10åˆ†)

æ¯ä¸ªåŒºé—´çš„è®ºæ–‡æ•°é‡ã€å˜ä½“åˆ†å¸ƒã€ç‰¹å¾åˆ†æã€‚

### 4. åŸå§‹è®ºæ–‡ vs å˜ä½“å¯¹æ¯”
- ç»Ÿè®¡æ£€éªŒï¼ˆt-testï¼‰
- æ¥å—ç‡å¯¹æ¯”
- å„ç»´åº¦å¾—åˆ†å¯¹æ¯”

### 5. å¯è§†åŒ–å›¾è¡¨

| å›¾è¡¨ | è¯´æ˜ |
|------|------|
| `rating_distribution.png` | è¯„åˆ†åˆ†å¸ƒç›´æ–¹å›¾ |
| `ratings_by_variant_boxplot.png` | å„å˜ä½“è¯„åˆ†ç®±çº¿å›¾ |
| `ratings_by_variant_violin.png` | å„å˜ä½“è¯„åˆ†å°æç´å›¾ |
| `decision_distribution.png` | å†³ç­–åˆ†å¸ƒé¥¼å›¾ |
| `aspect_ratings.png` | å„ç»´åº¦å¹³å‡åˆ†æŸ±çŠ¶å›¾ |
| `variant_decision_heatmap.png` | å˜ä½“-å†³ç­–çƒ­åŠ›å›¾ |
| `correlation_heatmap.png` | è¯„åˆ†ç»´åº¦ç›¸å…³æ€§çŸ©é˜µ |
| `text_length_vs_rating.png` | æ–‡æœ¬é•¿åº¦ä¸è¯„åˆ†æ•£ç‚¹å›¾ |

## ğŸ”§ é…ç½®é€‰é¡¹

### ä¿®æ”¹æ ·æœ¬å¤§å°

ç¼–è¾‘ `batch_evaluate_papers.py`:

```python
SAMPLE_SIZE = 200  # å¢åŠ åˆ°200ç¯‡
TRAIN_RATIO = 0.75  # è°ƒæ•´è®­ç»ƒ/æµ‹è¯•æ¯”ä¾‹
```

### ä¿®æ”¹è¯„åˆ†åŒºé—´

ç¼–è¾‘ `analyze_evaluation_results.py`:

```python
RATING_BINS = [0, 2, 4, 6, 8, 10]  # æ›´ç»†ç²’åº¦çš„åŒºé—´
RATING_LABELS = ['å¾ˆå·®', 'å·®', 'ä¸€èˆ¬', 'å¥½', 'å¾ˆå¥½']
```

### ä¿®æ”¹æ¨¡å‹å¤§å°

ç¼–è¾‘ `batch_evaluate_papers.py`:

```python
MODEL_SIZE = "4B"  # ä½¿ç”¨æ›´å°çš„æ¨¡å‹ï¼ˆæ›´å¿«ä½†å¯èƒ½ä¸å¤Ÿå‡†ç¡®ï¼‰
# æˆ–
MODEL_SIZE = "70B"  # ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹ï¼ˆæ›´å‡†ç¡®ä½†æ›´æ…¢ï¼‰
```

## ğŸ“ˆ å…¸å‹ä½¿ç”¨åœºæ™¯

### åœºæ™¯1ï¼šå¿«é€Ÿé¢„è§ˆ

ä½¿ç”¨5ç¯‡è®ºæ–‡å¿«é€Ÿæµ‹è¯•ï¼š

```python
# ä¿®æ”¹ batch_evaluate_papers.py
SAMPLE_SIZE = 5
```

### åœºæ™¯2ï¼šå®Œæ•´è¯„ä¼°

è¯„ä¼°å…¨éƒ¨100ç¯‡ï¼š

```bash
python scripts/batch_evaluate_papers.py
python scripts/analyze_evaluation_results.py
```

### åœºæ™¯3ï¼šæ·±åº¦åˆ†æ

è¯„ä¼°200ç¯‡å¹¶ç”Ÿæˆè¯¦ç»†æŠ¥å‘Šï¼š

```python
# ä¿®æ”¹ SAMPLE_SIZE = 200
python scripts/batch_evaluate_papers.py
python scripts/analyze_evaluation_results.py
```

## ğŸ“ è¾“å‡ºæ–‡ä»¶è¯´æ˜

### evaluation_results/ ç›®å½•

```
evaluation_results_20260207_143022.jsonl  - è¯¦ç»†è¯„ä¼°ç»“æœ
evaluation_summary_20260207_143022.json   - è¯„ä¼°æ‘˜è¦
```

### analysis_output/YYYYMMDD_HHMMSS/ ç›®å½•

```
overall_statistics.json           - æ€»ä½“ç»Ÿè®¡
variant_statistics.csv            - å˜ä½“ç»Ÿè®¡
rating_range_statistics.json      - è¯„åˆ†åŒºé—´ç»Ÿè®¡
original_vs_variants.json         - å¯¹æ¯”åˆ†æ
processed_data.csv                - å®Œæ•´å¤„ç†æ•°æ®
analysis_report.txt               - è¯¦ç»†æ–‡æœ¬æŠ¥å‘Š
*.png (8ä¸ªå›¾è¡¨)                   - å¯è§†åŒ–å›¾è¡¨
```

## ğŸ” æ•°æ®æ ¼å¼

### è¯„ä¼°ç»“æœ (JSONLæ ¼å¼)

```json
{
  "paper_id": "paper_123",
  "title": "è®ºæ–‡æ ‡é¢˜",
  "variant_type": "no_abstract",
  "dataset_split": "train",
  "evaluation": {
    "avg_rating": 7.5,
    "paper_decision": "Accept",
    "confidence": 4,
    "originality": 8,
    "quality": 7,
    "clarity": 7,
    "significance": 8,
    "strength": ["ä¼˜ç‚¹1", "ä¼˜ç‚¹2"],
    "weaknesses": ["ç¼ºç‚¹1", "ç¼ºç‚¹2"],
    "meta_review": "ç»¼åˆè¯„å®¡æ„è§..."
  },
  "text_length": 15234,
  "evaluation_timestamp": "2026-02-07T14:30:22"
}
```

## â“ å¸¸è§é—®é¢˜

### Q: è¯„ä¼°å¤ªæ…¢æ€ä¹ˆåŠï¼Ÿ
A: 
- å‡å°‘ `SAMPLE_SIZE`
- ä½¿ç”¨æ›´å°çš„ `MODEL_SIZE`
- ä½¿ç”¨GPUåŠ é€Ÿ

### Q: å†…å­˜ä¸è¶³ï¼Ÿ
A: 
- å‡å°‘ `SAMPLE_SIZE`
- åˆ†æ‰¹å¤„ç†
- å…³é—­å…¶ä»–ç¨‹åº

### Q: æ‰¾ä¸åˆ°è¯„ä¼°ç»“æœï¼Ÿ
A: 
- ç¡®è®¤å…ˆè¿è¡Œäº† `batch_evaluate_papers.py`
- æ£€æŸ¥ `evaluation_results/` ç›®å½•

### Q: å›¾è¡¨ä¸æ¸…æ™°ï¼Ÿ
A: 
ç¼–è¾‘ `analyze_evaluation_results.py`ï¼Œä¿®æ”¹DPI:
```python
plt.savefig(output_path / 'xxx.png', dpi=600)  # æé«˜åˆ°600
```

## ğŸ¯ æœ€ä½³å®è·µ

1. **å…ˆæµ‹è¯•**: è¿è¡Œ `test_evaluation_pipeline.py` ç¡®è®¤ç¯å¢ƒ
2. **å°æ ·æœ¬**: å…ˆç”¨5-10ç¯‡æµ‹è¯•æµç¨‹
3. **å®Œæ•´è¿è¡Œ**: å†ç”¨100ç¯‡å®Œæ•´è¯„ä¼°
4. **ä¿å­˜ç»“æœ**: åŠæ—¶å¤‡ä»½ `evaluation_results/` å’Œ `analysis_output/`
5. **åˆ†æå¯¹æ¯”**: å¤šæ¬¡è¿è¡Œå¯ä»¥å¯¹æ¯”ä¸åŒé…ç½®çš„æ•ˆæœ

## ğŸ“ æ³¨æ„äº‹é¡¹

- è¯„ä¼°éœ€è¦è”ç½‘ï¼ˆè°ƒç”¨LLM APIï¼‰
- ç»“æœæ–‡ä»¶ä½¿ç”¨æ—¶é—´æˆ³ï¼Œä¸ä¼šè¦†ç›–
- æ‰€æœ‰æ–‡æœ¬ä½¿ç”¨UTF-8ç¼–ç 
- å»ºè®®åœ¨è¿è¡Œå‰æ£€æŸ¥ç£ç›˜ç©ºé—´

## ğŸ†˜ è·å–å¸®åŠ©

å¦‚æœé‡åˆ°é—®é¢˜ï¼š
1. æŸ¥çœ‹ `scripts/README_EVALUATION.md` è¯¦ç»†æ–‡æ¡£
2. è¿è¡Œæµ‹è¯•è„šæœ¬è¯Šæ–­é—®é¢˜
3. æ£€æŸ¥é”™è¯¯æ—¥å¿—è¾“å‡º

---



