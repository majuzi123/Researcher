# batch_evaluate_papers.py é€»è¾‘è¯´æ˜

## ğŸ¯ æ ¸å¿ƒé€»è¾‘ï¼ˆç®€æ´ç‰ˆï¼‰

```
è¾“å…¥æ•°æ®é›† â†’ æŒ‰paper_idåˆ†ç»„ â†’ é‡‡æ ·Nä¸ªpaper_id â†’ è·å–æ‰€æœ‰å˜ä½“ â†’ é€ä¸€è¯„ä¼° â†’ ä¿å­˜ç»“æœ
```

## ğŸ“‹ æ‰§è¡Œæµç¨‹

### 1. åŠ è½½æ•°æ®
```python
train_papers = load_dataset("util/train_with_variants.jsonl")
test_papers = load_dataset("util/test_with_variants.jsonl")
```

### 2. æŒ‰paper_idåˆ†ç»„
```python
# æ¯ä¸ªpaper_idæœ‰6ä¸ªå˜ä½“
train_grouped = {
    "1706.03762": [
        {variant_type: "original", ...},
        {variant_type: "no_abstract", ...},
        {variant_type: "no_introduction", ...},
        {variant_type: "no_methods", ...},
        {variant_type: "no_experiments", ...},
        {variant_type: "no_conclusion", ...}
    ],
    ...
}
```

### 3. é‡‡æ ·
```python
# é…ç½®: SAMPLE_SIZE = 100
# è‡ªåŠ¨è®¡ç®—æ¯”ä¾‹ (ä¾‹å¦‚: trainæœ‰1234ä¸ªID, testæœ‰456ä¸ªID)
# æ¯”ä¾‹ = 1234/(1234+456) = 73%

# é‡‡æ ·:
sampled_train_ids = random.sample(train_paper_ids, 73)  # 73ä¸ªpaper_id
sampled_test_ids = random.sample(test_paper_ids, 27)    # 27ä¸ªpaper_id
```

### 4. è·å–æ‰€æœ‰å˜ä½“
```python
all_sampled = []
for paper_id in sampled_train_ids + sampled_test_ids:
    # è·å–è¯¥paper_idçš„æ‰€æœ‰6ä¸ªå˜ä½“
    for variant in grouped[paper_id]:
        all_sampled.append(variant)

# ç»“æœ: 100ä¸ªpaper_id Ã— 6ä¸ªå˜ä½“ = 600ç¯‡è®ºæ–‡
```

### 5. è¯„ä¼°
```python
for paper in all_sampled:  # 600ç¯‡
    review = reviewer.evaluate(paper['text'])
    result = {
        'paper_id': paper['paper_id'],
        'variant_type': paper['variant_type'],
        'evaluation': {
            'avg_rating': review['avg_rating'],
            'paper_decision': review['paper_decision'],
            'originality': review['originality'],
            'quality': review['quality'],
            'clarity': review['clarity'],
            'significance': review['significance'],
            ...
        }
    }
    results.append(result)
```

### 6. ä¿å­˜ç»“æœ
```python
# è¯¦ç»†æ•°æ® (JSONLæ ¼å¼ï¼Œæ¯è¡Œä¸€æ¡è®°å½•)
evaluation_results/evaluation_results_YYYYMMDD_HHMMSS.jsonl

# æ±‡æ€»ç»Ÿè®¡ (JSONæ ¼å¼)
evaluation_results/evaluation_summary_YYYYMMDD_HHMMSS.json
```

## âœ… å…³é”®ä¿è¯

1. **æ¯ä¸ªå˜ä½“æ•°é‡ç›¸åŒ**: æ¯ä¸ªå˜ä½“æ°å¥½100ç¯‡ï¼ˆå› ä¸ºé‡‡æ ·100ä¸ªpaper_idï¼Œæ¯ä¸ªæœ‰6ä¸ªå˜ä½“ï¼‰
2. **æ•°æ®å®Œæ•´**: æ¯æ¡è®°å½•åŒ…å«æ‰€æœ‰è¯„åˆ†å’Œå†³å®š
3. **å¯å¤ç°**: ä½¿ç”¨å›ºå®šéšæœºç§å­ï¼ˆSEED=42ï¼‰
4. **è‡ªåŠ¨æ¯”ä¾‹**: æ ¹æ®æ•°æ®é›†è‡ªåŠ¨è®¡ç®—train/testæ¯”ä¾‹

## ğŸ“Š è¾“å‡ºæ•°æ®ç¤ºä¾‹

### è¯¦ç»†æ•°æ® (evaluation_results_*.jsonl)
```json
{"paper_id": "1706.03762", "variant_type": "original", "evaluation": {"avg_rating": 7.8, ...}}
{"paper_id": "1706.03762", "variant_type": "no_abstract", "evaluation": {"avg_rating": 6.5, ...}}
{"paper_id": "1706.03762", "variant_type": "no_introduction", "evaluation": {"avg_rating": 6.2, ...}}
...
{"paper_id": "another_paper", "variant_type": "original", "evaluation": {...}}
...
```

### æ±‡æ€»ç»Ÿè®¡ (evaluation_summary_*.json)
```json
{
  "total_papers": 600,
  "variant_distribution": {
    "original": 100,
    "no_abstract": 100,
    "no_introduction": 100,
    "no_methods": 100,
    "no_experiments": 100,
    "no_conclusion": 100
  },
  "variant_statistics": {
    "original": {
      "count": 100,
      "avg_rating": 7.80,
      "accept_rate": 0.85,
      "avg_originality": 7.90,
      "avg_quality": 8.00,
      "avg_clarity": 7.70,
      "avg_significance": 7.80
    },
    "no_abstract": {
      "count": 100,
      "avg_rating": 6.30,
      "accept_rate": 0.58,
      ...
    },
    ...
  }
}
```

## ğŸ” ä¸æ–‡æ¡£å¯¹ç…§ç»“è®º

### âœ… å®Œå…¨ç¬¦åˆæ–‡æ¡£çš„éƒ¨åˆ†
- âœ… é‡‡æ ·é€»è¾‘: 100ä¸ªåŸºç¡€è®ºæ–‡ï¼Œæ¯ä¸ªåŒ…å«æ‰€æœ‰å˜ä½“
- âœ… æ•°æ®æ ¼å¼: JSONLè¯¦ç»†æ•°æ® + JSONæ±‡æ€»ç»Ÿè®¡
- âœ… å­—æ®µå†…å®¹: æ‰€æœ‰æ–‡æ¡£å£°ç§°çš„å­—æ®µéƒ½ç”Ÿæˆ
- âœ… è¾“å‡ºä½ç½®: evaluation_results/ ç›®å½•
- âœ… ç»Ÿè®¡è®¡ç®—: æ­£ç¡®è®¡ç®—å„å˜ä½“çš„ç»Ÿè®¡æ•°æ®

### âš ï¸ ä¸æ–‡æ¡£ä¸ä¸€è‡´çš„éƒ¨åˆ†
- âš ï¸ `TRAIN_RATIO`: æ–‡æ¡£è¯´0.8ï¼Œä»£ç æ˜¯Noneï¼ˆè‡ªåŠ¨è®¡ç®—ï¼‰
  - **å½±å“**: å®é™…æ¯”ä¾‹å–å†³äºæ•°æ®é›†ï¼Œè€Œéå›ºå®š80/20
  - **å·²ä¿®æ­£**: å·²æ›´æ–°æ–‡æ¡£è¯´æ˜

## ğŸ’¡ ä½¿ç”¨å»ºè®®

### å¦‚æœæƒ³è¦å›ºå®šæ¯”ä¾‹ï¼ˆå¦‚ 80/20ï¼‰
```python
# åœ¨ batch_evaluate_papers.py ä¸­ä¿®æ”¹:
TRAIN_RATIO = 0.8  # å›ºå®š80% train, 20% test
```

### å¦‚æœæƒ³è¦æ›´å¤šæ ·æœ¬
```python
SAMPLE_SIZE = 200  # 200ä¸ªåŸºç¡€è®ºæ–‡ Ã— 6å˜ä½“ = 1200æ¬¡è¯„ä¼°
```

### å¦‚æœæƒ³æŸ¥çœ‹ç‰¹å®šè®ºæ–‡çš„æ‰€æœ‰å˜ä½“
```python
python scripts/example_query_results.py
# ä¼šå±•ç¤ºå¦‚ä½•æŸ¥è¯¢å’Œåˆ†æç»“æœ
```

## ğŸ“š ç›¸å…³æ–‡æ¡£
- [LOGIC_VERIFICATION.md](./LOGIC_VERIFICATION.md) - è¯¦ç»†éªŒè¯æŠ¥å‘Š
- [DATA_FLOW_GUIDE.md](./DATA_FLOW_GUIDE.md) - å®Œæ•´æ•°æ®æµç¨‹
- [QUICK_REFERENCE.md](./QUICK_REFERENCE.md) - å¿«é€Ÿå‚è€ƒ

---
**æœ€åæ›´æ–°**: 2026-02-07  
**éªŒè¯çŠ¶æ€**: âœ… é€»è¾‘ä¸¥æ ¼æŒ‰æ–‡æ¡£å®ç°ï¼Œä»…é…ç½®è¯´æ˜æœ‰å°å·®å¼‚ï¼ˆå·²ä¿®æ­£ï¼‰

